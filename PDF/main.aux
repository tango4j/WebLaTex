\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{radford2019language,rao2022megatron}
\citation{vaswani2017attention}
\citation{devlin2018bert,raffel2019learning}
\citation{brown2020gpt3}
\citation{parmar2018image}
\citation{dosovitskiy2020image}
\citation{gulati2020conformer}
\citation{radford2023robust}
\citation{kitaev2019reformer}
\citation{dai2019transformer}
\citation{choromanski2020rethinking}
\citation{beltagy2020longformer}
\citation{xie2021segformer}
\citation{su2023roformer}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Transformer Variants for Efficiency}{1}{section*.1}\protected@file@percent }
\citation{vaswani2017attention}
\@writefile{toc}{\contentsline {paragraph}{Definition 1}{2}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 2}{2}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition 3}{2}{section*.4}\protected@file@percent }
\newlabel{par:permutation_invariance}{{1}{2}{Property 1 (\perminv )}{section*.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Property 1 (\emph  {Permutation Invariance})}{2}{section*.5}\protected@file@percent }
\newlabel{par:permutation_equivariance}{{1}{2}{Property 2 (\permeq )}{section*.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Property 2 (\emph  {Permutation Equivariance})}{2}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Property 3 (\emph  {Permutation Order-Equivariance Mapping-Invariance})}{2}{section*.7}\protected@file@percent }
\citation{vaswani2017attention,radford2019language}
\@writefile{toc}{\contentsline {paragraph}{Example 1 (\emph  {Permutation Order-Equivariance Mapping-Invariance})}{3}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Permutation Invariance/Equivariance for Multi-head Attention}{3}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Problem that SortFormer solves}{3}{section*.10}\protected@file@percent }
\newlabel{eq:sortformer_vector}{{14}{3}{Problem that SortFormer solves}{equation.1.14}{}}
\@writefile{toc}{\contentsline {paragraph}{Task Description}{4}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Contributions}{4}{section*.12}\protected@file@percent }
\citation{hershey2016deep}
\citation{zaheer2017deep}
\citation{zaheer2017deep}
\citation{lee2019set}
\citation{zaheer2017deep}
\citation{lee2019set}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Data Analysis Tasks and their Representations}}{5}{table.1}\protected@file@percent }
\newlabel{tab:tasks}{{1}{5}{Data Analysis Tasks and their Representations}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Prior Works}{5}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Clustering}{5}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Permutation Invariant Neural Networks}{5}{section*.14}\protected@file@percent }
\citation{kolbaek2017multitalker,yu2017permutation}
\citation{fujita2019end}
\citation{horiguchi2022encoder}
\bibdata{sortformer}
\bibcite{beltagy2020longformer}{{1}{2020}{{Beltagy et~al.}}{{Beltagy, Peters, and Cohan}}}
\bibcite{brown2020gpt3}{{2}{2020}{{Brown et~al.}}{{Brown, Mann, Ryder, Subramanian, Kaplan, Dhariwal, Neel, Shyam, Mishkin, and Radford}}}
\bibcite{choromanski2020rethinking}{{3}{2020}{{Choromanski et~al.}}{{Choromanski, Likhosherstov, Dohan, Song, Gane, Sarlos, Hawkins, Davis, Mohiuddin, Kaiser, et~al.}}}
\@writefile{toc}{\contentsline {paragraph}{Permutation Invariant Loss}{6}{section*.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Transformer Encoder}}{6}{figure.1}\protected@file@percent }
\newlabel{fig:subim1}{{1}{6}{Transformer Encoder}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces SortFormer Encoder}}{6}{figure.2}\protected@file@percent }
\newlabel{fig:subim2}{{2}{6}{SortFormer Encoder}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces SortFormer Example}}{6}{figure.3}\protected@file@percent }
\newlabel{fig:subim3}{{3}{6}{SortFormer Example}{figure.3}{}}
\bibcite{dai2019transformer}{{4}{2019}{{Dai et~al.}}{{Dai, Yang, Yang, Carbonell, Le, and Salakhutdinov}}}
\bibcite{devlin2018bert}{{5}{2018}{{Devlin et~al.}}{{Devlin, Chang, Lee, Niu, Toutanova, M.~Belinkov, Peters, Nair, and Poliakoff}}}
\bibcite{dosovitskiy2020image}{{6}{2020}{{Dosovitskiy et~al.}}{{Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.}}}
\bibcite{fujita2019end}{{7}{2019}{{Fujita et~al.}}{{Fujita, Kanda, Horiguchi, Xue, Nagamatsu, and Watanabe}}}
\bibcite{gulati2020conformer}{{8}{2020}{{Gulati et~al.}}{{Gulati, Qin, Chiu, Parmar, Zhang, Yu, Han, Wang, Zhang, Wu, et~al.}}}
\bibcite{hershey2016deep}{{9}{2016}{{Hershey et~al.}}{{Hershey, Chen, Le~Roux, and Watanabe}}}
\bibcite{horiguchi2022encoder}{{10}{2022}{{Horiguchi et~al.}}{{Horiguchi, Fujita, Watanabe, Xue, and Garcia}}}
\bibcite{kitaev2019reformer}{{11}{2019}{{Kitaev et~al.}}{{Kitaev, Kaiser, and Levskaya}}}
\bibcite{kolbaek2017multitalker}{{12}{2017}{{Kolb{\ae }k et~al.}}{{Kolb{\ae }k, Yu, Tan, and Jensen}}}
\bibcite{lee2019set}{{13}{2019}{{Lee et~al.}}{{Lee, Lee, Kim, Kosiorek, Choi, and Teh}}}
\bibcite{parmar2018image}{{14}{2018}{{Parmar et~al.}}{{Parmar, Vaswani, Uszkoreit, Jones, GÃ³mez, Polosukhin, Kaiser, and Polosukhin}}}
\bibcite{radford2019language}{{15}{2019}{{Radford et~al.}}{{Radford, Wu, Child, Luan, Amodei, Sutskever, et~al.}}}
\bibcite{radford2023robust}{{16}{2023}{{Radford et~al.}}{{Radford, Kim, Xu, Brockman, McLeavey, and Sutskever}}}
\bibcite{raffel2019learning}{{17}{2019}{{Raffel et~al.}}{{Raffel, Shazeer, Roberts, Lee, Parekh, and Narasimhan}}}
\bibcite{rao2022megatron}{{18}{2022}{{Rao et~al.}}{{Rao, Chen, Hendricks, Kreutzer, Li, Mishkin, Price, Puri, Qadir, Reddi, Shobhana, Talwar, Tay, Wang, Wei, Wilcox, Wu, Yuan, Zhang, and Zhou}}}
\bibcite{su2023roformer}{{19}{2023}{{Su et~al.}}{{Su, Ahmed, Lu, Pan, Bo, and Liu}}}
\bibcite{vaswani2017attention}{{20}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{xie2021segformer}{{21}{2021}{{Xie et~al.}}{{Xie, Wang, Yu, Anandkumar, Alvarez, and Luo}}}
\bibcite{yu2017permutation}{{22}{2017}{{Yu et~al.}}{{Yu, Kolb{\ae }k, Tan, and Jensen}}}
\bibcite{zaheer2017deep}{{23}{2017}{{Zaheer et~al.}}{{Zaheer, Kottur, Ravanbakhsh, Poczos, Salakhutdinov, and Smola}}}
\bibstyle{plainnat}
\gdef \@abspage@last{8}
